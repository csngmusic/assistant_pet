Данный проект будет содержать ассистента для студента, 
который будет отвечать на заданные ему вопросы, основываясь на переданной ему литературе.

1. Установить Tesseract OCR, путь к файлу заменить в config.py (переменная tess_path)
2. Установить Poppler для Windows, путь к файлу заменить в config.py (переменная poppler_path)
3. Установить Ollama для Windows.
4. Скачать LLM Gemma2:9b (ollama pull gemma2:9b). При установке другой модели обновить config.py (переменная model, указать название модели, например, mistral:7b)
5. Установить зависимости (pip install -r requirements.txt).
6. Установить расширение pgvector для PostgreSQL.
7. Создать хранилище данных (запустить скрипт в файле "db.sql" через консоль psql)
8. Прописать файл "config_db.py", заполнить его своими значениями (Структура приложена в файле "config_db_template.py")
9. Запустить сервер через uvicorn.

------------------------------------------------------------------------------------
Для добавления новых файлов запустить функцию "parse_text" из "books.py" (в консоли питона, либо вызвать в другом файле)

Запуск производится на порте 8080, пример запуска ниже:

uvicorn server:app --host 0.0.0.0 --port 8080 --reload

Запуск произведется в локальной сети на порте 8080. При изменении файлов сервер перезапустится.

------------------------------------------------------------------------------------
При первом открытии страницы запускается LLM, поэтому браузер может пожаловаться на невозможность открыть страницу. 
Это норма, через некоторое время запустится модель, а после страница. 
Для душевного спокойствия рекомендуется проверять используемые приложением ресурсы, будет видно, когда модель запустится.
При первом запуске сервера потребуется подключение к сети для установки модели для векторизации.
