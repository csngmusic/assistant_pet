Данный проект будет содержать ассистента для студента, 
который будет отвечать на заданные ему вопросы, основываясь на переданной ему литературе.

1. Установить Tesseract OCR, путь к файлу заменить в config.py
2. Установить Poppler для Windows, также заменить путь к файлу на свой
3. Установить Ollama для Windows.
4. Скачать LLM Gemma2:9b (ollama pull gemma2:9b). При установке другой модели обновить config.py
5. Установить зависимости (requirements.txt).
6. Установить расширение pgvector.
7. Создать хранилище данных (Скрипт в файле "db.sql")
8. Прописать файл "config_db.py" (Структура в "config_db_template.py")
9. Запустить сервер через uvicorn.

------------------------------------------------------------------------------------
Для добавления новых файлов запустить функцию "parse_text" из "books.py" (в консольке питона или вызвать в другом файле)
Запуск производится на порте 8080, пример запуска ниже:
uvicorn server:app --host 0.0.0.0 --port 8080 --reload
Запуск произведется в локальной сети на порте 8080. При изменении файлов сервер перезапустится.

------------------------------------------------------------------------------------
При первом открытии страницы запускается LLM, поэтому браузер может пожаловаться на невозможность открыть страницу. Это норма, через некоторое время запустится модель, а после страница. Для душевного спокойствия рекомендуется проверять используемые приложением ресурсы, будет видно, когда модель запустится.
При первом запуске сервера потребуется подключение к сети для установки модели для векторизации.